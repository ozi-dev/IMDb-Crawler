{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86nDI6DwabbI",
        "outputId": "b1848877-a219-4ead-f641-8c7f19cd3be3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sqlite3.Cursor at 0x7f0b9edf2b20>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Author: Oğuzhan Öztürk to get contact: oguzhanozturk0@outlook.com\n",
        "\n",
        "import sqlite3\n",
        "connection = sqlite3.connect('SQLITE DB')\n",
        "crsr = connection.cursor()\n",
        "crsr.execute(\"CREATE TABLE  yourTableName( rating int, review text)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "87_qxQtdolzh",
        "outputId": "0a779468-db5f-4399-d847-1dba887b2363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scrapy in /usr/local/lib/python3.8/dist-packages (2.7.1)\n",
            "Requirement already satisfied: parsel>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from scrapy) (1.7.0)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.8/dist-packages (from scrapy) (38.0.4)\n",
            "Requirement already satisfied: itemadapter>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from scrapy) (0.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from scrapy) (21.3)\n",
            "Requirement already satisfied: service-identity>=18.1.0 in /usr/local/lib/python3.8/dist-packages (from scrapy) (21.1.0)\n",
            "Requirement already satisfied: w3lib>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from scrapy) (2.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from scrapy) (57.4.0)\n",
            "Requirement already satisfied: itemloaders>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from scrapy) (1.0.6)\n",
            "Requirement already satisfied: queuelib>=1.4.2 in /usr/local/lib/python3.8/dist-packages (from scrapy) (1.6.2)\n",
            "Requirement already satisfied: protego>=0.1.15 in /usr/local/lib/python3.8/dist-packages (from scrapy) (0.2.1)\n",
            "Requirement already satisfied: zope.interface>=5.1.0 in /usr/local/lib/python3.8/dist-packages (from scrapy) (5.5.2)\n",
            "Requirement already satisfied: cssselect>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from scrapy) (1.2.0)\n",
            "Requirement already satisfied: lxml>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from scrapy) (4.9.1)\n",
            "Requirement already satisfied: PyDispatcher>=2.0.5 in /usr/local/lib/python3.8/dist-packages (from scrapy) (2.0.6)\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.8/dist-packages (from scrapy) (3.4.0)\n",
            "Requirement already satisfied: Twisted>=18.9.0 in /usr/local/lib/python3.8/dist-packages (from scrapy) (22.10.0)\n",
            "Requirement already satisfied: pyOpenSSL>=21.0.0 in /usr/local/lib/python3.8/dist-packages (from scrapy) (22.1.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=3.3->scrapy) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=3.3->scrapy) (2.21)\n",
            "Requirement already satisfied: jmespath>=0.9.5 in /usr/local/lib/python3.8/dist-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from protego>=0.1.15->scrapy) (1.15.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.8/dist-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.8/dist-packages (from service-identity>=18.1.0->scrapy) (0.2.8)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.8/dist-packages (from service-identity>=18.1.0->scrapy) (22.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.8/dist-packages (from Twisted>=18.9.0->scrapy) (4.4.0)\n",
            "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.8/dist-packages (from Twisted>=18.9.0->scrapy) (15.1.0)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.8/dist-packages (from Twisted>=18.9.0->scrapy) (21.0.0)\n",
            "Requirement already satisfied: incremental>=21.3.0 in /usr/local/lib/python3.8/dist-packages (from Twisted>=18.9.0->scrapy) (22.10.0)\n",
            "Requirement already satisfied: Automat>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from Twisted>=18.9.0->scrapy) (22.10.0)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.8/dist-packages (from hyperlink>=17.1.1->Twisted>=18.9.0->scrapy) (2.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->scrapy) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from tldextract->scrapy) (2.23.0)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.8/dist-packages (from tldextract->scrapy) (1.5.1)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.8/dist-packages (from tldextract->scrapy) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.1.0->tldextract->scrapy) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Using cached urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "Installing collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.13\n",
            "    Uninstalling urllib3-1.26.13:\n",
            "      Successfully uninstalled urllib3-1.26.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "selenium 4.7.2 requires urllib3[socks]~=1.26, but you have urllib3 1.25.11 which is incompatible.\u001b[0m\n",
            "Successfully installed urllib3-1.25.11\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r0% [2 InRelease gpgv 1,581 B] [Connecting to archive.ubuntu.com] [Connecting to\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [2 InRelease gpgv 1,581 B] [Connecting to archive.ubuntu.com] [Waiting for h\r                                                                               \rHit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.8/dist-packages (4.7.2)\n",
            "Collecting urllib3[socks]~=1.26\n",
            "  Using cached urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.8/dist-packages (from selenium) (0.9.2)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.8/dist-packages (from selenium) (0.22.0)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.8/dist-packages (from selenium) (2022.9.24)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (1.0.4)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (22.1.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.8/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Installing collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.25.11\n",
            "    Uninstalling urllib3-1.25.11:\n",
            "      Successfully uninstalled urllib3-1.25.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.13 which is incompatible.\u001b[0m\n",
            "Successfully installed urllib3-1.26.13\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (108.0.5359.71-0ubuntu0.18.04.5).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 21 not upgraded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:37<00:00,  1.18s/it]\n",
            "100%|██████████| 795/795 [00:15<00:00, 52.65it/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install scrapy\n",
        "!apt-get update\n",
        "!pip install selenium\n",
        "!apt install chromium-chromedriver\n",
        "\n",
        "from scrapy.selector import Selector\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome('chromedriver',options=options)\n",
        "\n",
        "import numpy as np\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "url = 'IMBD MOVIE COMMENT PAGE URL e.g: https://www.imdb.com/title/tt0047478/reviews/?ref_=tt_ov_rt'\n",
        "driver.get(url)\n",
        "\n",
        "sel = Selector(text = driver.page_source)\n",
        "review_counts = sel.css('.lister .header span::text').extract_first().replace(',','').split(' ')[0]\n",
        "more_review_pages = int(int(review_counts)/25)\n",
        "\n",
        "body = driver.find_element(By.CSS_SELECTOR, 'body')\n",
        "for i in tqdm(range(more_review_pages)):\n",
        "    try:\n",
        "        body.send_keys(Keys.PAGE_DOWN)\n",
        "        time.sleep(1)\n",
        "        body.send_keys(Keys.PAGE_DOWN)\n",
        "        \n",
        "\n",
        "        css_selector = 'load-more-trigger'\n",
        "        driver.find_element(By.ID, css_selector).click()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "reviews = driver.find_elements(By.CSS_SELECTOR, 'div.review-container')\n",
        "first_review = reviews[0]\n",
        "sel2 = Selector(text = first_review.get_attribute('innerHTML'))\n",
        "\n",
        "\n",
        "\n",
        "def data_insert():\n",
        "  crsr.execute(\"INSERT INTO yourTableName(rating, review) VALUES (?, ?)\", \n",
        "               (rating,review))\n",
        "\n",
        "\n",
        "error_url_list = []\n",
        "error_msg_list = []\n",
        "\n",
        "for d in tqdm(reviews):\n",
        "    try:\n",
        "        sel2 = Selector(text = d.get_attribute('innerHTML'))\n",
        "        try:\n",
        "            rating = sel2.css('.rating-other-user-rating span::text').extract_first()\n",
        "        except:\n",
        "            rating = np.NaN\n",
        "        try:\n",
        "            review = sel2.css('.text.show-more__control::text').extract_first()\n",
        "        except:\n",
        "            review = np.NaN\n",
        "\n",
        "\n",
        "        data_insert()\n",
        "\n",
        "    except Exception as e:\n",
        "        error_url_list.append(url)\n",
        "        error_msg_list.append(e)\n",
        "\n",
        "res = crsr.execute(\"SELECT* FROM yourTableName\")\n",
        "\n",
        "res.fetchall()\n",
        "\n",
        "connection.commit()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
